{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca606a33",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ca0b9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load Data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Data Visualisation\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model Training\n",
    "from tensorflow.keras import utils  \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78788aaa",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa89ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"D:\\ds3 asl project\\asl_alphabet_train\\asl_alphabet_train\"\n",
    "test_dir = r\"D:\\ds3 asl project\\asl_alphabet_test\\asl_alphabet_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2fa8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir) :\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    dir_list = os.listdir(data_dir)\n",
    "    for i in range(len(dir_list)):\n",
    "        print(\"Obtaining images of\", dir_list[i], \"...\")\n",
    "        for image in os.listdir(data_dir + \"/\" + dir_list[i]):\n",
    "            img = cv2.imread(data_dir + '/' + dir_list[i] + '/' + image)\n",
    "            img = cv2.resize(img, (32, 32))\n",
    "            images.append(img)\n",
    "            labels.append(i)\n",
    "    \n",
    "    return images, labels\n",
    "        \n",
    "X, y = get_data(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d58c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a04266",
   "metadata": {},
   "source": [
    "# Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f4421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', \n",
    "           'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n",
    "           'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89daa2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_images():\n",
    "    figure = plt.figure()\n",
    "    plt.figure(figsize=(16,5))\n",
    "\n",
    "    for i in range (0,29):\n",
    "        plt.subplot(3,10,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        path = train_dir + \"/{0}/{0}1.jpg\".format(classes[i])\n",
    "        img = plt.imread(path)\n",
    "        plt.imshow(img)\n",
    "        plt.xlabel(classes[i])\n",
    "        \n",
    "plot_sample_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78033f28",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e3fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X, y):\n",
    "    np_X = np.array(X)\n",
    "    normalised_X = np_X.astype('float32')/255.0\n",
    "    \n",
    "    label_encoded_y = utils.to_categorical(y)\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(normalised_X, label_encoded_y, test_size = 0.1)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = preprocess_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5769fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data:\", x_train.shape)\n",
    "print(\"Test data:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c4b570",
   "metadata": {},
   "source": [
    "# Define CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 29\n",
    "batch = 32\n",
    "epochs = 15\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same', input_shape=(32, 32, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b71d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee6a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c2baa",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=batch, epochs=epochs, validation_split=0.2, shuffle = True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myModel2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10ac6fb",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e334f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90ab24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model):\n",
    "\n",
    "  plt.figure(figsize=(12, 12))\n",
    "  plt.subplot(3, 2, 1)\n",
    "  plt.plot(history.history['accuracy'], label = 'train_accuracy')\n",
    "  plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.legend()\n",
    "  plt.subplot(3, 2, 2)\n",
    "  plt.plot(history.history['loss'], label = 'train_loss')\n",
    "  plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "        \n",
    "plot_results(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705eadb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d236f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "as11 = r\"C:\\Users\\tijil\\Desktop\\3rd sem\\IC 272\\just_check_dataset_ds3\\A\\A\\WhatsApp Image 2022-11-13 at 5.15.16 PM\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2baa816",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "as1 = get_data(as11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0002f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "as1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da61c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(as1[0]),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf7021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(as1), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53dd920",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_image = cv2.resize(cv2.imread(r\"C:\\Users\\tijil\\Desktop\\3rd sem\\IC 272\\just_check_dataset_ds3\\A\\A\\WhatsApp Image 2022-11-13 at 5.15.16 PM\", cv2.IMREAD_GRAYSCALE),  (32, 32))\n",
    "\n",
    "test1_image = np.array(test1_image).reshape( -1, 32, 32, 1)\n",
    "\n",
    "prediction = model.predict({x_train : test1_image })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5678f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import sys\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\tijil\\anaconda3\\pkgs\\imageio-2.19.3-py39haa95532_0\\Lib\\site-packages\\imageio\\plugins\")\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(r\"C:\\Users\\tijil\\Desktop\\3rd sem\\IC 272\\just_check_dataset_ds3\\A\\A\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "IMG_DIR = r\"C:\\Users\\tijil\\Desktop\\3rd sem\\IC 272\\just_check_dataset_ds3\\A\\A\"\n",
    "print(IMG_DIR)\n",
    "\n",
    "for img in os.listdir(IMG_DIR):\n",
    "    img_array = cv2.imread(os.path.join(IMG_DIR,img), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    img_pil = Image.fromarray(img_array)\n",
    "    img_32x32 = np.array(img_pil.resize((32, 32), Image.ANTIALIAS))\n",
    "\n",
    "    img_array = (img_32x32.flatten())\n",
    "\n",
    "    img_array  = img_array.reshape(-1,1).T\n",
    "\n",
    "    print(img_array)\n",
    "    \n",
    "    img = tensorflow.reshape((img_array),shape=(-1, 32, 32, 1))\n",
    "    \n",
    "    y_val_pred=model.predict(img)\n",
    "    y_val_pred=np.argmax(y_val_pred,axis=1)\n",
    "    print(y_val_pred)\n",
    "    \n",
    "\n",
    "    with open('fish-train1.csv', 'ab') as f:\n",
    "\n",
    "        np.savetxt(f, img_array, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378f0827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f72547",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tensorflow.reshape((img_array),shape=(-1, 32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eacbb09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd85aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b453f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred=model.predict(img)\n",
    "y_val_pred=np.argmax(y_val_pred,axis=1)\n",
    "print(classification_report(y_val_pred,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa2d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(img)\n",
    "np.argmax(prediction,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea74c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img1 = cv2.imread(r\"C:\\Users\\tijil\\Desktop\\3rd sem\\IC 272\\just_check_dataset_ds3\\A\\A\")\n",
    "img1 = cv2.resize(img1, (-1, 32, 32, 1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
